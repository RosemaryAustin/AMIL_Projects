{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lynn He - T03-09 [00] Regression Project [Colab]",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RosemaryAustin/AMIL_Projects/blob/master/Lynn_He_T03_09_%5B00%5D_Regression_Project_%5BColab%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSdG7cSNFro-",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FdRu8E0F6EJ"
      },
      "source": [
        "# Regression Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mm5d3zEpKE00"
      },
      "source": [
        "In this project you will be divided into small groups (two or three people). You will be pointed to a dataset and asked to create a model to solve a problem. Over the course of the day, your team will explore the data and train the best model you can for solving the problem. At the end of the day, your team will give a short presentation about your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2iIQ-XduKJZz"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-TOrwufKQhD"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Apply scikit-learn or TensorFlow to a dataset to create a regression model.\n",
        "* Preprocess data for feeding into a model.\n",
        "* Use a hand-built model to make predictions.\n",
        "* Measure the quality of predictions from your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LqnO7DiKmwi"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Introduction to Colab\n",
        "* Intermediate Python\n",
        "* Intermediate Pandas\n",
        "* Visualizations\n",
        "* Regression\n",
        "* Regression with scikit-learn\n",
        "* Regression with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3qhlIRMGLDea"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "330 minutes (285 minutes working time, 45 minutes for presentations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nb9YD_6cWefp"
      },
      "source": [
        "### Deliverables\n",
        "\n",
        "1. A copy of this Colab notebook containing your code and responses to the ethical considerations below.\n",
        "1. A group presentation. After everyone is done, we will ask each group to stand in front of the class and give a brief presentation about what they have done in this lab. The presentation can be a code walkthrough, a group discussion, a slide show, or any other means that conveys what you did over the course of the day and what you learned. If you do create any artifacts for your presentation, please share them in the class folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZj2NF0gLGjp"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "This project is graded in separate sections that each contribute a percentage of the total score:\n",
        "\n",
        "1. Building and Using a Model (80%)\n",
        "1. Ethical Implications (10%)\n",
        "1. Project Presentation (10%)\n",
        "\n",
        "#### Building and Using a Model\n",
        "\n",
        "There are 6 demonstrations of competency listed in the problem statement below. Each competency is graded on a 3 point scale for a total of 18 available points. The following rubric will be used:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency, but in an incorrect manner |\n",
        "| 2      | Attempted competency correctly, but sub-optimally |\n",
        "| 3      | Successful demonstration of competency |\n",
        "\n",
        "The demonstrations of competency show that the team knows how to use the tools of a data scientist, but they are not a good judge of \"thinking like a data scientist\". 3 additional points will be graded on the teams demonstration of skillful application of data science concepts and graded on the following rubric:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Created a generic model with little insight |\n",
        "| 2      | Performed some basic data science processes and patterns |\n",
        "| 3      | Demonstrated mastery of data science and exploration concepts learned so far |\n",
        "\n",
        "#### Ethical Implications\n",
        "\n",
        "There are six questions in the **Ethical Implications** secion. Each question is worth 2 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at question or answer was off-topic or didn't make sense |\n",
        "| 1      | Question was answered, but answer missed important considerations  |\n",
        "| 2      | Answer adequately considered ethical implications |\n",
        "\n",
        "#### Project Presentation\n",
        "\n",
        "The project presentation will be graded on participation. All members of a team should actively participate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JzEoFw-TPi7r"
      },
      "source": [
        "## Team\n",
        "\n",
        "Please enter your team members names in the placeholders in this text area:\n",
        "\n",
        "*   Rosemary Austin\n",
        "*   Amanda Ma\n",
        "*  Lynn He\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NkF2j1JBJaM2"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kGWV97GDJfiD"
      },
      "source": [
        "## Exercise 1: Coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cr12EFb2WQym"
      },
      "source": [
        "[Kaggle](http://www.kaggle.com) hosts a [dataset containing intake and outcome data](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes) for the [Austin Animal Care Shelter](http://www.austintexas.gov/department/aac). In this project we will **use intake data to predict the number of days that an animal is likely to stay in the shelter before being adopted**.\n",
        "\n",
        "You are free to use any toolkit that we have covered in this class to solve the problem. That should be at least scikit-learn and TensorFlow.\n",
        "\n",
        "Important details:\n",
        "\n",
        "* The [dataset](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes) offers three files, one for intakes, one for outcomes, and one that joins the two and adds some additional columns. Feel free to use any combination of the files.\n",
        "* The column we are trying to predict is 'time_in_shelter_days'.\n",
        "* Do not use any outcome data as features for training the model. We want to be able to predict the time in shelter for any given animal at intake.\n",
        "* Not all animals have outcomes. Not all outcomes are adoption.\n",
        "\n",
        "**Graded** demonstrations of competency:\n",
        "1. Get the data into a Python object.\n",
        "1. The ability to examine the data programmatically and visually.\n",
        "1. Perform at least one preprocessing transformation on the data.\n",
        "1. Creation and training of a regression model.\n",
        "1. Testing and/or scoring of a model.\n",
        "1. Model experimentation and tuning: record parameters and objects used along with resulting scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgFU38b7rfbv"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZqD0Nts4ffc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOdOl0qqPyL-",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA2hASwn4cGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intakes = pd.read_csv('aac_intakes.csv')\n",
        "in_out = pd.read_csv('aac_intakes_outcomes.csv')\n",
        "# outcomes = pd.read_csv('aac_outcomes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewb1caIp4xeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7bHD6iyPZyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out['time_in_shelter_days'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rky9x3QOsBXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# in_out.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXhVlWudPLSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMJYKkxGTWJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OqPu2HJJTNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "animal_list = ['Dog', 'Cat', 'Bird', 'Other']\n",
        "sex_outcomes = ['Neutered Male', 'Spayed Female', 'Intact Female', 'Intact Male', 'Unknown']\n",
        "in_out['animal_categories'] = in_out.animal_type.apply(lambda x: animal_list.index(x))\n",
        "in_out['sex_intakes_categories'] = in_out.sex_upon_intake.apply(lambda x: sex_outcomes.index(x) if type(x) is str else 4)\n",
        "\n",
        "in_out = in_out[(in_out['time_in_shelter_days']>=0) & (in_out['time_in_shelter_days']<=57)]\n",
        "in_out = in_out[['intake_month','intake_year','time_in_shelter_days',\n",
        "                 'animal_categories','sex_intakes_categories']]\n",
        "in_out.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfdFgjB2B3Dd",
        "colab_type": "text"
      },
      "source": [
        "##Preparing data for TensorFlow regression models\n",
        "\n",
        "We created a 100% sample to avoid issues with sorting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokiGdSXB1Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out = in_out.sample(frac = 1)\n",
        "in_out.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0m6nBZv9DLQ",
        "colab_type": "text"
      },
      "source": [
        "##Spliting dataframe\n",
        "We split the data into training and testing: 20% for testing, 80% for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UICWke6TCIiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_size = int(len(in_out) * .2)\n",
        "\n",
        "testing_df = in_out[:test_set_size]\n",
        "training_df = in_out[test_set_size:]\n",
        "\n",
        "print(\"Holding out {} records for testing. Using {} records for training.\".format(len(testing_df), len(training_df)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2toA_jf9Qfk",
        "colab_type": "text"
      },
      "source": [
        "##Translating Dataframes to Datasets\n",
        "\n",
        "To create the models, we used **TensorFlow** and translated the dataframes into datasets so that we can feed it into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-KIfDbMCgrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.data import Dataset\n",
        "\n",
        "testing_ds = Dataset.from_tensor_slices(testing_df)\n",
        "training_ds = Dataset.from_tensor_slices(training_df)\n",
        "\n",
        "testing_ds, training_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3tsKmqL99o-",
        "colab_type": "text"
      },
      "source": [
        "##Implementing a [Gradient Descent Optimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBaEJkv2ilp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "gd_optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
        "\n",
        "gd_optimizer = tf.contrib.estimator.clip_gradients_by_norm(gd_optimizer, clip_norm = 5.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ea5hl-6mTLv",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression with Animal Type\n",
        "\n",
        "We tested if we could run categorical columns as a feature, first with just animal types and a linear regression mdoel. The **RMSE** was the metric by which we measured the accuracy of our models, keeping in mind that the average days in shelter was around 16.  \n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "We found that a batch size of 100 repeated 5 times was computationally efficient. Altering these variables did not significantly alter the **RMSE of around 14**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDnZaFQDf54F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn import metrics\n",
        "\n",
        "animal_type_feature_col = tf.feature_column.categorical_column_with_identity(\n",
        "key = 'animal_type',\n",
        "num_buckets = 4)\n",
        "\n",
        "def training_input():\n",
        "  features = {\n",
        "      'animal_type': training_df['animal_categories']\n",
        "  }\n",
        "  \n",
        "  labels = training_df['time_in_shelter_days']\n",
        "  training_ds = Dataset.from_tensor_slices((features,labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "def testing_input():\n",
        "  features = {\n",
        "      'animal_type': testing_df['animal_categories']\n",
        "  }\n",
        "  \n",
        "  testing_ds = Dataset.from_tensor_slices(features)\n",
        "  testing_ds = testing_ds.batch(1)\n",
        "\n",
        "  return testing_ds\n",
        "\n",
        "features = [animal_type_feature_col]\n",
        "\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=features,\n",
        "    optimizer = gd_optimizer\n",
        "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
        ")\n",
        "\n",
        "# Train the model\n",
        "linear_regressor.train(\n",
        " input_fn=training_input\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predictions = linear_regressor.predict(\n",
        "  input_fn=testing_input,\n",
        ")\n",
        "\n",
        "# Convert the predctions to a NumPy array\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Find the RMSE\n",
        "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['time_in_shelter_days']))\n",
        "root_mean_squared_error\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNk87riZmqyu",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression with[link text](https://) Intake Month and Intake Year\n",
        "\n",
        "Now that we know that categorical data as a feature works, we wanted to try putting in different features to decrease our RMSE of the model with just the animal type (~14.7). \n",
        "\n",
        "We wanted to try the top features that the lasso regression found:\n",
        "\n",
        "**1.intake_month**\n",
        "\n",
        "**2.intake_year**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lja0nzmpLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from sklearn import metrics\n",
        "\n",
        "def training_input():\n",
        "  features = {\n",
        "      'intake_month': training_df['intake_month'],\n",
        "      'intake_year': training_df['intake_year']\n",
        "  }\n",
        "  \n",
        "  labels = training_df['time_in_shelter_days']\n",
        "  training_ds = Dataset.from_tensor_slices((features,labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "def testing_input():\n",
        "  features = {\n",
        "      'intake_month': testing_df['intake_month'],\n",
        "      'intake_year': testing_df['intake_year']\n",
        "  }\n",
        "  \n",
        "  testing_ds = Dataset.from_tensor_slices(features)\n",
        "  testing_ds = testing_ds.batch(1)\n",
        "\n",
        "  return testing_ds\n",
        "\n",
        "features = [tf.feature_column.numeric_column('intake_month'),\n",
        "           tf.feature_column.numeric_column('intake_year')]\n",
        "\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=features,\n",
        "    optimizer = gd_optimizer\n",
        "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
        ")\n",
        "\n",
        "# Train the model\n",
        "linear_regressor.train(\n",
        " input_fn=training_input\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predictions = linear_regressor.predict(\n",
        "  input_fn=testing_input,\n",
        ")\n",
        "\n",
        "# Convert the predctions to a NumPy array\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Find the RMSE\n",
        "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['time_in_shelter_days']))\n",
        "root_mean_squared_error\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LfhgM6r1D6I",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression with Categorical Variables: Animal Type and Sex Upon Intake\n",
        "\n",
        "It seems that the RMSE is much improved: **~11.9**. Intake Month and Intake Year are better predictors than just animal type. Now let's try **animal_type** combined with **sex_upon_intake**\n",
        "\n",
        "RMSE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuUyhW2Uz0lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "animal_type_feature_col = tf.feature_column.categorical_column_with_identity(\n",
        "key = 'animal_type',\n",
        "num_buckets = 4)\n",
        "\n",
        "sex_upon_intake_feature_col = tf.feature_column.categorical_column_with_identity(\n",
        "key = 'sex_upon_intake',\n",
        "num_buckets = 5)\n",
        "\n",
        "def training_input():\n",
        "  features = {\n",
        "      'animal_type': training_df['animal_categories'],\n",
        "      'sex_upon_intake': training_df['sex_intakes_categories']\n",
        "  }\n",
        "  \n",
        "  labels = training_df['time_in_shelter_days']\n",
        "  training_ds = Dataset.from_tensor_slices((features,labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "def testing_input():\n",
        "  features = {\n",
        "      'animal_type': testing_df['animal_categories'],\n",
        "      'sex_upon_intake': testing_df['sex_intakes_categories']\n",
        "  }\n",
        "  \n",
        "  testing_ds = Dataset.from_tensor_slices(features)\n",
        "  testing_ds = testing_ds.batch(1)\n",
        "\n",
        "  return testing_ds\n",
        "\n",
        "features = [animal_type_feature_col,sex_upon_intake_feature_col]\n",
        "\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=features,\n",
        "    optimizer = gd_optimizer\n",
        "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
        ")\n",
        "\n",
        "# Train the model\n",
        "linear_regressor.train(\n",
        " input_fn=training_input\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predictions = linear_regressor.predict(\n",
        "  input_fn=testing_input,\n",
        ")\n",
        "\n",
        "# Convert the predctions to a NumPy array\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Find the RMSE\n",
        "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['time_in_shelter_days']))\n",
        "root_mean_squared_error\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sIQfDzvCzjD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Oh no! The RMSE is worse: **~14.7**. But still better than the model with just the animal type. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0X9-sGG1gMU",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression with Animal Type, Sex Upon Intake, Intake Month, Intake Year\n",
        "\n",
        "Let's try all of them!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVajE9UH1e0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "animal_type_feature_col = tf.feature_column.categorical_column_with_identity(\n",
        "key = 'animal_type',\n",
        "num_buckets = 4)\n",
        "\n",
        "sex_upon_intake_feature_col = tf.feature_column.categorical_column_with_identity(\n",
        "key = 'sex_upon_intake',\n",
        "num_buckets = 5)\n",
        "\n",
        "def training_input():\n",
        "  features = {\n",
        "      'animal_type': training_df['animal_categories'],\n",
        "      'sex_upon_intake': training_df['sex_intakes_categories'],\n",
        "      'intake_year': training_df['intake_year'],\n",
        "      'intake_month': training_df['intake_month']\n",
        "  }\n",
        "  \n",
        "  labels = training_df['time_in_shelter_days']\n",
        "  training_ds = Dataset.from_tensor_slices((features,labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "def testing_input():\n",
        "  features = {\n",
        "      'animal_type': testing_df['animal_categories'],\n",
        "      'sex_upon_intake': testing_df['sex_intakes_categories'],\n",
        "      'intake_year': testing_df['intake_year'],\n",
        "      'intake_month': testing_df['intake_month']\n",
        "  }\n",
        "  \n",
        "  testing_ds = Dataset.from_tensor_slices(features)\n",
        "  testing_ds = testing_ds.batch(1)\n",
        "\n",
        "  return testing_ds\n",
        "\n",
        "features = [animal_type_feature_col,\n",
        "            sex_upon_intake_feature_col,\n",
        "           tf.feature_column.numeric_column('intake_year'),\n",
        "           tf.feature_column.numeric_column('intake_month')]\n",
        "\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=features,\n",
        "    optimizer = gd_optimizer\n",
        "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
        ")\n",
        "\n",
        "# Train the model\n",
        "linear_regressor.train(\n",
        " input_fn=training_input\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predictions = linear_regressor.predict(\n",
        "  input_fn=testing_input,\n",
        ")\n",
        "\n",
        "# Convert the predctions to a NumPy array\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Find the RMSE\n",
        "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['time_in_shelter_days']))\n",
        "root_mean_squared_error\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADdB8d9XDKuV",
        "colab_type": "text"
      },
      "source": [
        "The RMSE is similar to the model with intake month and intake year: **~11.9**. \n",
        "\n",
        "Howoever, after re-running the cell that splits the dataframe into testing and training dataframes several times to ensure randomness, we find that the model with all four variables usually comes out with a prediction which is ~.03 better than the model with just intake month and intake year. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na1yApBuA6-Q",
        "colab_type": "text"
      },
      "source": [
        "##Troubleshooting RMSE: Looking into Predictions for Individual Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiD1N3Gt_vdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is the plot of reality vs predictions\n",
        "#The vertical is time in shelter in days and horizotal is the type of animal\n",
        "\n",
        "plt.scatter(testing_df['animal_categories'], testing_df['time_in_shelter_days'])\n",
        "\n",
        "\n",
        "plt.scatter(testing_df['animal_categories'], predictions)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsJqEctLBo4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The horizotal is the sex of the animal when brought into the shelter and vertical is time in days\n",
        "plt.scatter(testing_df['sex_intakes_categories'],testing_df['time_in_shelter_days'])\n",
        "\n",
        "\n",
        "plt.scatter(testing_df['sex_intakes_categories'],predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAnPVHKtBynh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.scatter(testing_df['intake_year'],testing_df['time_in_shelter_days'])\n",
        "\n",
        "\n",
        "plt.scatter(testing_df['intake_year'],predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBI1gQ1B6yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The horizotal is the month the animal was brought into the shelter and the vertical is time in shelter via days\n",
        "\n",
        "plt.scatter(testing_df['intake_month'],testing_df['time_in_shelter_days'])\n",
        "plt.scatter(testing_df['intake_month'],predictions) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv1ewand1VKf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B2OkbjaHmicA"
      },
      "source": [
        "**Iterations**\n",
        "\n",
        "Record different attempts at model configurations here:\n",
        "\n",
        "| Model                        | Parameters                | Score         |\n",
        "|------------------------------|---------------------------|---------------|\n",
        "| sklearn LinearRegressor      | none                      | R^2 = 0.00123 |\n",
        "| sklearn SGDRegressor         | batch_size=50, epochs=100 | R^2 = 0.00011 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elj4C5iH1Usp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxXecyKaKI4z"
      },
      "source": [
        "## Exercise 2: Ethical Implications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uK8XzfVHLi1K"
      },
      "source": [
        "Even the most basic of models have the potential to affect segments of the population in different ways. It is important to consider how your model might positively and negative effect different types of users.\n",
        "\n",
        "In this section of the project you will reflect on the positive and negative implications of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezdLjd0BKeDF"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_U3L0F9FLmwa"
      },
      "source": [
        "**Positive Impact**\n",
        "\n",
        "Your model is trying to solve a problem. Think about who will benefit from that problem being solved and write a brief narrative about how the model will help.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g582VerYL0so"
      },
      "source": [
        "*Hypothetical entities will benefit because...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALr018eQMuUw"
      },
      "source": [
        "**Negative Impact**\n",
        "\n",
        "Models don't often have universal benefit. Think about who might be negatively impacted by the predictions your model is making. This person or persons might not be directly using the model, but instead might be impacted indirectly.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We8_W4WtNDLw"
      },
      "source": [
        "*Hypothetical entity will be negatively impacted because...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07J-8ljpL85I"
      },
      "source": [
        "**Bias**\n",
        "\n",
        "Models can be bias for many reasons. The bias can come from the data used to build the model (eg. sampling, data collection methods, available sources) and from the interpretation of the predictions generated by the model.\n",
        "\n",
        "Think of at least two ways that bias might have been introduced to your model and explain both below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jg_PSw3NMyFX"
      },
      "source": [
        "*One source of bias in the model could be...*\n",
        "\n",
        "*Another source of bias in the model could be...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7j9AWdJLMTJI"
      },
      "source": [
        "**Changing the Dataset to Mitigate Bias**\n",
        "\n",
        "Bias datasets are one of the primary ways in which bias is introduced to a machine learning model. Look back at the input data that you fed to your model. Think about how you might change something about the data to reduce bias in your model.\n",
        "\n",
        "What change or changes could you make to your dataset less bias? Consider the data that you have, how and where that data was collected, and what other sources of data might be used to reduce bias.\n",
        "\n",
        "Write a summary of change that could be made to your input data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yzzfrQ-xNZo5"
      },
      "source": [
        "*Since the data has potential bias A we can adjust...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ePs6hpLiMNSx"
      },
      "source": [
        "**Changing the Model to Mitigate Bias**\n",
        "\n",
        "Is there any way to reduce bias by changing the model itself? This could include modifying algorithmic choices, tweaking hyperparameters, etc.\n",
        "\n",
        "Write a brief summary of changes that you could make to help reduce bias in your model.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bZ3PS8bRNRCv"
      },
      "source": [
        "*Since the model has potential bias A we can adjust...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYY7lk55MgdX"
      },
      "source": [
        "**Mitigating Bias Downstream**\n",
        "\n",
        "Models make predictions. Downstream processes make decisions. What processes and/or rules should be in place for people and systems interpreting and acting on the results of your model to reduce the bias? Describe these below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mp3TkmalNcR-"
      },
      "source": [
        "*Since the predictions have potential bias A we can adjust...*"
      ]
    }
  ]
}